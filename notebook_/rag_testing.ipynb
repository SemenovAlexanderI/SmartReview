{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6f28c70",
   "metadata": {},
   "source": [
    "**SmartReview** ‚Äî RAG demo (Jupyter Notebook)\n",
    "\n",
    "–¶–µ–ª—å: –ø–æ–∫–∞–∑–∞—Ç—å –ø—Ä–æ—Å—Ç—É—é RAG-—Å–∏—Å—Ç–µ–º—É –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –æ—Ç–∑—ã–≤–æ–≤:\n",
    "- –∫–∞–∫ –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –æ—Ç–∑—ã–≤–æ–≤ (`amazon_polarity`).\n",
    "- –∫–∞–∫ —Å–æ–∑–¥–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ Qdrant —Å –∏–Ω–¥–µ–∫—Å–æ–º –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—é.\n",
    "- –∫–∞–∫ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –Ω–∞–±–æ—Ä chain'–µ–π/–∞–≥–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∂–∞–ª–æ–±, –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏—á–∏–Ω –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø–ª—é—Å–æ–≤/–º–∏–Ω—É—Å–æ–≤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff471322",
   "metadata": {},
   "source": [
    "# loading data  into vector storage Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d1f48c",
   "metadata": {},
   "source": [
    "# import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39bb08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Imports\n",
    "# - –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ/—É—Ç–∏–ª–∏—Ç–∞—Ä–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
    "# - –†–∞–±–æ—Ç–∞ —Å –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏\n",
    "# - LangChain / Qdrant / OpenAI ‚Äî –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è RAG\n",
    "# - Pydantic ‚Äî —Å—Ç—Ä–æ–≥–æ—Å—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä–∞\n",
    "# -------------------------\n",
    "import os\n",
    "from typing import List, Dict\n",
    "\n",
    "# –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
    "from datasets import load_dataset\n",
    "\n",
    "# LangChain –∏ Qdrant\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# –ü—Ä–æ–≤–∞–π–¥–µ—Ä embeddings –∏ LLM (OpenAI)\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "\n",
    "# Qdrant: –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∏ –∫–ª–∏–µ–Ω—Ç\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models # –í–∞–∂–Ω–æ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏ —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e33127f",
   "metadata": {},
   "source": [
    "# 1 c–ø–æ—Å–æ–± –∑–∞–¥–∞—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∂–æ—Å—Ç–≤–∫–æ –≤ –∫–æ–¥–µ –∫–∞–∫ —Ç—É—Ç \n",
    "# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---\n",
    "# os.environ[\"OPENAI_API_KEY\"] = ...\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = ...\n",
    "os.environ[\"QDRANT_URL\"] = ...\n",
    "os.environ[\"QDRANT_API_KEY\"] = ...\n",
    "COLLECTION_NAME = \"amazon_complaints\"\n",
    "def get_qdrant_client():\n",
    "    return QdrantClient(url=os.environ['QDRANT_URL'], api_key=os.environ['QDRANT_API_KEY'], timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca27c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4c5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 —Å–ø–æ—Å–æ–± - —ç—Ç–æ –ø–æ–¥–≥—Ä—É–∑–∏—Ç—å –ø–µ—Ä–µ–º–µ–Ω—ã–µ –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è .env —Ñ–∞–π–ª–∞\n",
    "\n",
    "# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "\n",
    "# –ø—Ä–∏–º–µ—Ä –∫–∞–∫ –±—É–¥—É—Ç –∑—Ä–∞–Ω–∏—Ç—å—Å—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ .env —Ñ–∞–π–ª–µ\n",
    "# OPENAI_API_KEY=sk-...\n",
    "# QDRANT_URL=https://...\n",
    "# QDRANT_API_KEY=eyJh...\n",
    "# COLLECTION_NAME=amazon_complaints\n",
    "# LANGSMITH_PROJECT=Amazon Product Analysis\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e694d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• (MIXED) ---\n",
    "\n",
    "def load_balanced_data(limit_per_class=100):\n",
    "    \"\"\"\n",
    "    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É –æ—Ç–∑—ã–≤–æ–≤ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ `amazon_polarity`.\n",
    "\n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "        limit_per_class: int\n",
    "            –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ (positive/negative).\n",
    "\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "        List[Document] ‚Äî —Å–ø–∏—Å–æ–∫ langchain Document —Å –ø–æ–ª—è–º–∏ page_content –∏ metadata.\n",
    "            metadata —Å–æ–¥–µ—Ä–∂–∏—Ç: original_title, sentiment ('positive'|'negative'), label (0|1).\n",
    "\n",
    "    –ü—Ä–∏–º–µ—á–∞–Ω–∏—è:\n",
    "    - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è streaming=True –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏.\n",
    "    - –ï—Å–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç –∏–∑–º–µ–Ω–∏—Ç—Å—è, –∫–æ–¥ –º–æ–∂–µ—Ç –∑–∞–≤–µ—Ä—à–∏—Ç—å—Å—è —Ä–∞–Ω—å—à–µ, –µ—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –ø—Ä–∏–º–µ—Ä–æ–≤.\n",
    "    \"\"\"\n",
    "    print(f\"-> –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–ø–æ {limit_per_class} —à—Ç. –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞)...\")\n",
    "    dataset = load_dataset(\"amazon_polarity\", split=\"train\", streaming=True)\n",
    "    \n",
    "    processed_docs = []\n",
    "    neg_count = 0\n",
    "    pos_count = 0\n",
    "    \n",
    "    for row in dataset:\n",
    "        label = row['label'] # 0: neg, 1: pos\n",
    "        \n",
    "        # –õ–æ–≥–∏–∫–∞ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏\n",
    "        if label == 0 and neg_count >= limit_per_class:\n",
    "            continue\n",
    "        if label == 1 and pos_count >= limit_per_class:\n",
    "            continue\n",
    "        \n",
    "        sentiment = \"negative\" if label == 0 else \"positive\"\n",
    "        # –§–æ—Ä–º–∏—Ä—É–µ–º –µ–¥–∏–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º –∏ —Å–æ–¥–µ—Ä–∂–∏–º—ã–º\n",
    "        text_content = f\"Title: {row['title']}\\nReview: {row['content']}\"\n",
    "        \n",
    "        # –°–æ–∑–¥–∞–µ–º Document —Å –Ω—É–∂–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏\n",
    "        doc = Document(\n",
    "            page_content=text_content,\n",
    "            metadata={\n",
    "                \"original_title\": row['title'],\n",
    "                \"sentiment\": sentiment, # –ö–ª—é—á–µ–≤–æ–µ –ø–æ–ª–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏\n",
    "                \"label\": label\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # –°—á–∏—Ç–∞–µ–º –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã\n",
    "        if label == 0:\n",
    "            neg_count += 1\n",
    "        else:\n",
    "            pos_count += 1\n",
    "            \n",
    "        processed_docs.append(doc)\n",
    "        \n",
    "        if neg_count >= limit_per_class and pos_count >= limit_per_class:\n",
    "            break\n",
    "            \n",
    "    print(f\"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(processed_docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (Neg: {neg_count}, Pos: {pos_count})\")\n",
    "    return processed_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1889c3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–ø–æ 500 —à—Ç. –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.' thrown while requesting GET https://huggingface.co/datasets/amazon_polarity/resolve/9d9c45c18f8c3cf1b23a3c27917b60cbf28f3289/amazon_polarity/train-00000-of-00004.parquet\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 25afe6a5-9d19-4307-a906-d37dae0e56fe)')' thrown while requesting GET https://huggingface.co/datasets/amazon_polarity/resolve/9d9c45c18f8c3cf1b23a3c27917b60cbf28f3289/amazon_polarity/train-00000-of-00004.parquet\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.' thrown while requesting GET https://huggingface.co/datasets/amazon_polarity/resolve/9d9c45c18f8c3cf1b23a3c27917b60cbf28f3289/amazon_polarity/train-00000-of-00004.parquet\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.' thrown while requesting GET https://huggingface.co/datasets/amazon_polarity/resolve/9d9c45c18f8c3cf1b23a3c27917b60cbf28f3289/amazon_polarity/train-00000-of-00004.parquet\n",
      "Retrying in 4s [Retry 3/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∂–µ–Ω–æ 1000 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (Neg: 500, Pos: 500)\n"
     ]
    }
   ],
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è)\n",
    "docs = load_balanced_data(limit_per_class=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746c1464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. –í–ï–ö–¢–û–†–ù–û–ï –•–†–ê–ù–ò–õ–ò–©–ï ---\n",
    "\n",
    "def get_qdrant_client():\n",
    "    \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ Qdrant\"\"\"\n",
    "    return QdrantClient(url=os.environ['QDRANT_URL'], api_key=os.environ['QDRANT_API_KEY'], timeout=3600)\n",
    "\n",
    "def setup_vector_store(docs: List[Document]):\n",
    "    \"\"\"\n",
    "    –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ Qdrant –∏ —Å–æ–∑–¥–∞–µ—Ç payload index –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ sentiment.\n",
    "\n",
    "    –ü–æ–≤–µ–¥–µ–Ω–∏–µ:\n",
    "    - –°–æ–∑–¥–∞–µ—Ç –∫–æ–ª–ª–µ–∫—Ü–∏—é (force_recreate=True) ‚Äî –ø–µ—Ä–µ–∑–∞–ø–∏—à–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é —Å —Ç–µ–º –∂–µ –∏–º–µ–Ω–µ–º.\n",
    "    - –°–æ–∑–¥–∞—ë—Ç payload index –¥–ª—è 'metadata.sentiment', —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã—Å—Ç—Ä–æ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ 'positive'/'negative'.\n",
    "    \"\"\"\n",
    "    client = get_qdrant_client()\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    \n",
    "    print(f\"-> –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é '{COLLECTION_NAME}'...\")\n",
    "    \n",
    "    # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ–∫—Ç–æ—Ä—ã (—ç—Ç–æ —Å–æ–∑–¥–∞–µ—Ç –∫–æ–ª–ª–µ–∫—Ü–∏—é, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç, –∏–ª–∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–µ—Ç –ø—Ä–∏ force_recreate)\n",
    "    vector_store = QdrantVectorStore.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embeddings,\n",
    "        url=os.environ['QDRANT_URL'],\n",
    "        api_key=os.environ['QDRANT_API_KEY'],\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        force_recreate=True\n",
    "    )\n",
    "\n",
    "    # 2. –í–ê–ñ–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –°–æ–∑–¥–∞–µ–º Payload Index\n",
    "    # Qdrant —Ç—Ä–µ–±—É–µ—Ç —è–≤–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è –ø–æ–ª–µ–π, –ø–æ –∫–æ—Ç–æ—Ä—ã–º –º—ã –±—É–¥–µ–º —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å\n",
    "    print(\"-> –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è –ø–æ–ª—è 'metadata.sentiment'...\")\n",
    "    \n",
    "    client.create_payload_index(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        field_name=\"metadata.sentiment\", # –ü—É—Ç—å –∫ –ø–æ–ª—é –≤ JSON-—Å—Ç—Ä—É–∫—Ç—É—Ä–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞\n",
    "        field_schema=models.PayloadSchemaType.KEYWORD # KEYWORD = —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (–¥–ª—è —Å—Ç—Ä–æ–∫ —Ç–∏–ø–∞ 'positive'/'negative')\n",
    "    )\n",
    "    \n",
    "    print(\"-> –ò–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω. –•—Ä–∞–Ω–∏–ª–∏—â–µ –≥–æ—Ç–æ–≤–æ.\")\n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c80bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é 'amazon_complaints_2'...\n",
      "‚öôÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è –ø–æ–ª—è 'metadata.sentiment'...\n",
      "–ò–Ω–¥–µ–∫—Å —Å–æ–∑–¥–∞–Ω. –•—Ä–∞–Ω–∏–ª–∏—â–µ –≥–æ—Ç–æ–≤–æ.\n"
     ]
    }
   ],
   "source": [
    "# 2. –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è\n",
    "vector_store = setup_vector_store(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1867731",
   "metadata": {},
   "source": [
    "#AGENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086f7ba9",
   "metadata": {},
   "source": [
    "# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ê–≥–µ–Ω—Ç–∞: Semantic Routing\n",
    "–í–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã –∑–∞–¥–∞–≤–∞—Ç—å –æ–¥–∏–Ω –æ–±—â–∏–π –ø—Ä–æ–º–ø—Ç, –º—ã —Å–æ–∑–¥–∞–µ–º **—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ü–µ–ø–æ—á–∫–∏ (Skills)** –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á.\n",
    "\n",
    "–ú—ã —Ä–µ–∞–ª–∏–∑—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω **Router**:\n",
    "1.  **Classifier (Router):** LLM –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç (JSON), –≤—ã–±–∏—Ä–∞—è –Ω—É–∂–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç (`complaints`, `root_cause`).\n",
    "2.  **Specialized Chains:**\n",
    "\n",
    "    - *`build_complaint_chain`* ‚Äî retriever —Å —Ñ–∏–ª—å—Ç—Ä–æ–º negative, —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –∫—Ä–∞—Ç–∫–∏–π —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–±–ª–µ–º.\n",
    "    - *`build_root_cause_chain`* ‚Äî –≥–ª—É–±–∏–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑, –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (k=8).\n",
    "    - *`build_comparative_chain`* ‚Äî –≤—ã—Ç—è–≥–∏–≤–∞–µ—Ç –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –æ—Ç–∑—ã–≤—ã –∏ –ø—Ä–æ—Å–∏—Ç —Å–¥–µ–ª–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É –ø–ª—é—Å—ã/–º–∏–Ω—É—Å—ã.\n",
    "    - *`build_general_chain`* ‚Äî fallback, –æ–±—â–∏–π –ø–æ–º–æ—â–Ω–∏–∫.\n",
    "\n",
    "## –°–æ–∑–¥–∞–Ω–∏–µ Router Agent\n",
    "–ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º `with_structured_output` (Function Calling), —á—Ç–æ–±—ã –∑–∞—Å—Ç–∞–≤–∏—Ç—å LLM –≤—ã–±—Ä–∞—Ç—å –æ–¥–∏–Ω –∏–∑ –ø—Ä–µ–¥–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ (`RouteQuery`). –≠—Ç–æ –∏—Å–∫–ª—é—á–∞–µ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac8b38",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from typing import List, Literal\n",
    "\n",
    "# –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
    "from datasets import load_dataset\n",
    "\n",
    "# LangChain –∏ Qdrant\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "\n",
    "# Pydantic ‚Äî –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ —Ä–æ—É—Ç–µ—Ä–∞\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefafca3",
   "metadata": {},
   "source": [
    "\n",
    "import os\n",
    "\n",
    "os.environ['LANGSMITH_ENDPOINT']=...\n",
    "os.environ['LANGSMITH_API_KEY']=...\n",
    "os.environ['OPENAI_API_KEY']=......\n",
    "os.environ['TAVILY_API_KEY']=...\n",
    "COLLECTION_NAME=\"amazon_complaints_2\"\n",
    "os.environ['LANGSMITH_PROJECT']=\"AMAZON product analysis\"\n",
    "os.environ[\"QDRANT_URL\"]=...\n",
    "os.environ['QDRANT_API_KEY']=...\n",
    "os.environ[\"LANGCHAIN_TRACING\"]=\"true\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64ffd70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff651c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ –ê–≥–µ–Ω—Ç –≥–æ—Ç–æ–≤! –í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å (–∏–ª–∏ 'exit').\n",
      "–ü—Ä–∏–º–µ—Ä—ã: 'What are the bugs with audio?', 'Should I buy this?', 'Why is delivery so bad?'\n",
      "üö¶ Router decided: Routing to -> [COMPARISON]\n",
      "\n",
      "Agent:\n",
      "–í–æ—Ç —Ç–∞–±–ª–∏—Ü–∞ \"–ü–ª—é—Å—ã vs –ú–∏–Ω—É—Å—ã\" –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤:\n",
      "\n",
      "| –ü–ª—é—Å—ã                                      | –ú–∏–Ω—É—Å—ã                                      |\n",
      "|--------------------------------------------|---------------------------------------------|\n",
      "| –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Å–±–æ—Ä–∫–∏ –∏ —É–ø–∞–∫–æ–≤–∫–∏         | –ù–∏–∑–∫–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∏ –ø–ª–æ—Ö–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ   |\n",
      "| –£–¥–æ–±—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è                      | –ù–µ–ø—Ä–∏—è—Ç–Ω—ã–π –∑–∞–ø–∞—Ö —Ä–µ–∑–∏–Ω—ã                     |\n",
      "| –î–æ—Å—Ç—É–ø–Ω–∞—è —Ü–µ–Ω–∞                             | –ù–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ —É–º–µ–Ω—å—à–µ–Ω–∏–∏ –æ–±—ä–µ–º–∞         |\n",
      "| –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –¥–µ—Ç–µ–π                         | –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∏ —Ñ–æ—Ä–º–∞                 |\n",
      "| –£–¥–æ–±–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –ø—Ä–æ—Å—Ç–æ—Ç–∞ –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏  | –ß—É–≤—Å—Ç–≤—É–µ—Ç—Å—è –¥–µ—à–µ–≤–∏–∑–Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞              |\n",
      "| –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã (–¥–ª—è –¥–µ—Ç–µ–π)          | –î–æ–ª–≥–æ–µ –≤—Ä–µ–º—è –¥–æ—Å—Ç–∞–≤–∫–∏                        |\n",
      "| –•–æ—Ä–æ—à–∞—è —ç—Ä–≥–æ–Ω–æ–º–∏–∫–∞                         | –ù–µ–ø–æ–¥—Ö–æ–¥—è—â–∏–π –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —Å–∏–¥—è—á–µ–º –ø–æ–ª–æ–∂–µ–Ω–∏–∏ |\n",
      "| –î–æ–ª–≥–æ–≤–µ—á–Ω–æ—Å—Ç—å –∏ –ø—Ä–æ—á–Ω–æ—Å—Ç—å                  | –ü–ª–æ—Ö–∏–µ —É—Å–ª–æ–≤–∏—è –≤–æ–∑–≤—Ä–∞—Ç–∞                     |\n",
      "\n",
      "### –í—ã–≤–æ–¥ –æ –ø–æ–∫—É–ø–∫–µ:\n",
      "–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤, –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥, —á—Ç–æ —Å—Ç–æ–∏—Ç —Ç—â–∞—Ç–µ–ª—å–Ω–æ –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –∫–∞–∂–¥—É—é –ø–æ–∫—É–ø–∫—É. –ï—Å–ª–∏ –≤—ã –∏—â–µ—Ç–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —Å–ª—É–∂–∏—Ç—å –¥–æ–ª–≥–æ –∏ —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è—Ç—å –≤–∞—à–∏ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏, —Å—Ç–æ–∏—Ç –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–∑—ã–≤—ã –∏ —É—á–∏—Ç—ã–≤–∞—Ç—å –≤–æ–∑–º–æ–∂–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏. –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –≤—ã —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç–µ –ø–æ–∫—É–ø–∫—É –∫–∞–º–µ—Ä—ã –∏–ª–∏ –∫–æ—Ä—Å–µ—Ç–∞, –±—É–¥—å—Ç–µ –≥–æ—Ç–æ–≤—ã –∫ –≤–æ–∑–º–æ–∂–Ω—ã–º –ø—Ä–æ–±–ª–µ–º–∞–º —Å –∫–∞—á–µ—Å—Ç–≤–æ–º –∏ –∫–æ–º—Ñ–æ—Ä—Ç–æ–º. –í —Ç–æ –∂–µ –≤—Ä–µ–º—è, –µ—Å–ª–∏ –≤—ã –∏—â–µ—Ç–µ –º–µ–±–µ–ª—å –∏–ª–∏ –∏–≥—Ä—É—à–∫–∏ –¥–ª—è –¥–µ—Ç–µ–π, –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–∑—ã–≤—ã –º–æ–≥—É—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ —Ç–æ, —á—Ç–æ –ø—Ä–æ–¥—É–∫—Ç —Å—Ç–æ–∏—Ç —Å–≤–æ–∏—Ö –¥–µ–Ω–µ–≥. –í –∫–æ–Ω–µ—á–Ω–æ–º –∏—Ç–æ–≥–µ, —Ä–µ—à–µ–Ω–∏–µ –æ –ø–æ–∫—É–ø–∫–µ –¥–æ–ª–∂–Ω–æ –æ—Å–Ω–æ–≤—ã–≤–∞—Ç—å—Å—è –Ω–∞ –≤–∞—à–∏—Ö –ª–∏—á–Ω—ã—Ö –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—è—Ö –∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è—Ö.\n"
     ]
    }
   ],
   "source": [
    "# –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞ Qdrant\n",
    "def get_qdrant_client():\n",
    "    return QdrantClient(url=os.environ['QDRANT_URL'], api_key=os.environ['QDRANT_API_KEY'], timeout=120)\n",
    "\n",
    "# –ü–æ–ª—É—á–µ–Ω–∏–µ LLM\n",
    "def get_llm():\n",
    "    return ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# --- 1. –°–¢–†–û–ò–¢–ï–õ–ò –¶–ï–ü–û–ß–ï–ö (CHAIN BUILDERS) ---\n",
    "\n",
    "def build_complaint_chain(vector_store):\n",
    "    \"\"\"Story 1: –ü–æ–∏—Å–∫ –∂–∞–ª–æ–± (Negative Filter)\"\"\"\n",
    "\n",
    "    # –ñ–µ—Å—Ç–∫–∏–π —Ñ–∏–ª—å—Ç—Ä –Ω–∞ —É—Ä–æ–≤–Ω–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö\n",
    "    filter_condition = models.Filter(\n",
    "        must=[models.FieldCondition(key=\"metadata.sentiment\", match=models.MatchValue(value=\"negative\"))]\n",
    "    )\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 5, \"filter\": filter_condition})\n",
    "    \n",
    "    template = \"\"\"–ù–∞–π–¥–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ—Ç–∞–ª–∏ –∂–∞–ª–æ–± –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ —Ç–µ–º–µ –≤–æ–ø—Ä–æ—Å–∞.\n",
    "    –ö–æ–Ω—Ç–µ–∫—Å—Ç (—Ç–æ–ª—å–∫–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –æ—Ç–∑—ã–≤—ã): {context}\n",
    "    –í–æ–ø—Ä–æ—Å: {question}\n",
    "    –û—Ç–≤–µ—Ç (–∫—Ä–∞—Ç–∫–æ –ø–µ—Ä–µ—á–∏—Å–ª–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã):\"\"\"\n",
    "    \n",
    "    return (\n",
    "        {\"context\": retriever | (lambda docs: \"\\n\".join([d.page_content for d in docs])), \"question\": RunnablePassthrough()}\n",
    "        | ChatPromptTemplate.from_template(template)\n",
    "        | get_llm()\n",
    "        | StrOutputParser()\n",
    "    ).with_config({\"run_name\": \"ComplaintsChain\"})\n",
    "\n",
    "def build_root_cause_chain(vector_store):\n",
    "    \"\"\"Story 2: –ì–ª—É–±–∏–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏—á–∏–Ω (Negative Filter + Deep Prompt)\"\"\"\n",
    "\n",
    "    filter_condition = models.Filter(\n",
    "        must=[models.FieldCondition(key=\"metadata.sentiment\", match=models.MatchValue(value=\"negative\"))]\n",
    "    )\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 8, \"filter\": filter_condition})\n",
    "    \n",
    "    template = \"\"\"–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π Product Manager. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—Ç–∑—ã–≤—ã –∏ –æ–±—ä—è—Å–Ω–∏, –ü–û–ß–ï–ú–£ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –Ω–µ–¥–æ–≤–æ–ª—å–Ω—ã.\n",
    "    –í—ã—è–≤–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (–∫–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞, –æ–ø–∏—Å–∞–Ω–∏–µ, –¥–æ—Å—Ç–∞–≤–∫–∞).\n",
    "    \n",
    "    –û—Ç–∑—ã–≤—ã: {context}\n",
    "    –¢–µ–º–∞: {question}\n",
    "    \n",
    "    –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç:\"\"\"\n",
    "    \n",
    "    return (\n",
    "        {\"context\": retriever | (lambda docs: \"\\n\\n\".join([d.page_content for d in docs])), \"question\": RunnablePassthrough()}\n",
    "        | ChatPromptTemplate.from_template(template)\n",
    "        | get_llm()\n",
    "        | StrOutputParser()\n",
    "    ).with_config({\"run_name\": \"RootChain\"})\n",
    "\n",
    "def build_comparative_chain(vector_store):\n",
    "    \"\"\"Story 3: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ (Parallel Retrieval)\"\"\"\n",
    "\n",
    "    # –°–æ–∑–¥–∞–µ–º –¥–≤–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞: –¥–ª—è –ø–ª—é—Å–æ–≤ –∏ –¥–ª—è –º–∏–Ω—É—Å–æ–≤\n",
    "    neg_filter = models.Filter(must=[models.FieldCondition(key=\"metadata.sentiment\", match=models.MatchValue(value=\"negative\"))])\n",
    "    neg_retriever = vector_store.as_retriever(search_kwargs={\"k\": 5, \"filter\": neg_filter})\n",
    "    \n",
    "    pos_filter = models.Filter(must=[models.FieldCondition(key=\"metadata.sentiment\", match=models.MatchValue(value=\"positive\"))])\n",
    "    pos_retriever = vector_store.as_retriever(search_kwargs={\"k\": 5, \"filter\": pos_filter})\n",
    "    \n",
    "    template = \"\"\"–°—Ä–∞–≤–Ω–∏ –æ–ø—ã—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ —Ç–µ–º–µ: {topic}.\n",
    "    –ù–ï–ì–ê–¢–ò–í: {neg_context}\n",
    "    –ü–û–ó–ò–¢–ò–í: {pos_context}\n",
    "    –ó–∞–¥–∞—á–∞: –¢–∞–±–ª–∏—Ü–∞ \"–ü–ª—é—Å—ã vs –ú–∏–Ω—É—Å—ã\" –∏ –≤—ã–≤–æ–¥ –æ –ø–æ–∫—É–ø–∫–µ.\"\"\"\n",
    "    \n",
    "    def format_list(docs):\n",
    "        return \"\\n\".join([f\"- {d.page_content}\" for d in docs])\n",
    "\n",
    "    return (\n",
    "        {\n",
    "            \"neg_context\": neg_retriever | format_list,\n",
    "            \"pos_context\": pos_retriever | format_list,\n",
    "            \"topic\": RunnablePassthrough()\n",
    "        }\n",
    "        | ChatPromptTemplate.from_template(template)\n",
    "        | get_llm()\n",
    "        | StrOutputParser()\n",
    "    ).with_config({\"run_name\": \"ComparativeChain\"})\n",
    "\n",
    "def build_general_chain():\n",
    "    \"\"\"General Purpose Chain (No Filtering)\"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç SmartReview. –û—Ç–≤–µ—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –≤–µ–∂–ª–∏–≤–æ.\\n–í–æ–ø—Ä–æ—Å: {question}\"\n",
    "    )\n",
    "    return prompt | get_llm() | StrOutputParser()\n",
    "\n",
    "# --- 2. ROUTING LOGIC (–ú–ê–†–®–†–£–¢–ò–ó–ê–¢–û–†) ---\n",
    "\n",
    "# –û–ø–∏—Å—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞, —á—Ç–æ–±—ã –æ–Ω –Ω–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∏—Ä–æ–≤–∞–ª\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫—É–¥–∞ –Ω–∞–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\"\"\"\n",
    "    destination: Literal[\"complaints\", \"root_cause\", \"comparison\", \"general\"] = Field(\n",
    "        ...,\n",
    "        description=\"–í—ã–±–µ—Ä–∏: 'complaints' (–±–∞–≥–∏/–∂–∞–ª–æ–±—ã), 'root_cause' (–ø—Ä–∏—á–∏–Ω—ã –ø—Ä–æ–±–ª–µ–º), 'comparison' (—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ/–ø–æ–∫—É–ø–∫–∞) –∏–ª–∏ 'general'.\"\n",
    "    )\n",
    "\n",
    "def create_router_agent(vector_store):\n",
    "    llm = get_llm()\n",
    "    \n",
    "    # 1. –°–æ–∑–¥–∞–µ–º \"—É–º–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞\" —Å –ø–æ–º–æ—â—å—é structured output\n",
    "    # –≠—Ç–æ –∑–∞—Å—Ç–∞–≤–ª—è–µ—Ç LLM –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å JSON —Å –ø–æ–ª–µ–º destination\n",
    "    structured_llm_router = llm.with_structured_output(RouteQuery)\n",
    "    \n",
    "    system_prompt = \"\"\"You are an expert router for a product analysis tool.\n",
    "    Route the user's query to one of three destinations:\n",
    "    \n",
    "    1. 'complaints': Use this when the user asks \"what is wrong\", \"find bugs\", \"list issues\", \"complaints about X\".\n",
    "    2. 'root_cause': Use this when the user asks \"WHY is it bad\", \"explain the reason\", \"analyze the failure\".\n",
    "    3. 'comparison': Use this when the user asks \"pros and cons\", \"should I buy\", \"compare good and bad\", \"is it worth it\".\n",
    "    \n",
    "    Return only the destination.\"\"\"\n",
    "    \n",
    "    router_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ])\n",
    "    \n",
    "    # –°–∞–º–∞ —Ü–µ–ø–æ—á–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "    router_chain = (router_prompt | structured_llm_router).with_config({\"run_name\": \"RouterClassifier\"}) # <-- –í LangSmith –±—É–¥–µ—Ç –≤–∏–¥–Ω–æ —ç—Ç–æ –∏–º—è\n",
    "\n",
    "    # 2. –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –≤—Å–µ—Ö –Ω–∞—à–∏—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤\n",
    "    chain_tools = {\n",
    "        \"complaints\": build_complaint_chain(vector_store),\n",
    "        \"root_cause\": build_root_cause_chain(vector_store),\n",
    "        \"comparison\": build_comparative_chain(vector_store),\n",
    "        \"general\": build_general_chain(),\n",
    "    }\n",
    "\n",
    "    # 3. –§—É–Ω–∫—Ü–∏—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ (–ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏–µ –æ—Ç LLM –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –Ω—É–∂–Ω—É—é —Ü–µ–ø–æ—á–∫—É)\n",
    "    def route_logic(info):\n",
    "        # info - —ç—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã router_chain (–æ–±—ä–µ–∫—Ç RouteQuery)\n",
    "        destination = info.destination\n",
    "        print(f\"-> –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä –≤—ã–±—Ä–∞–ª: -> [{destination.upper()}]\")\n",
    "        return chain_tools[destination]\n",
    "\n",
    "    # 4. –§–∏–Ω–∞–ª—å–Ω–∞—è \"–ú–∞–≥–∏—á–µ—Å–∫–∞—è\" —Ü–µ–ø–æ—á–∫–∞\n",
    "    # –°–Ω–∞—á–∞–ª–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º -> –ø–µ—Ä–µ–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ route_logic -> –∑–∞–ø—É—Å–∫–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é —Ü–µ–ø–æ—á–∫—É\n",
    "    full_chain =  {\n",
    "        \"destination\": router_chain,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    } | RunnableLambda(lambda x: route_logic(x[\"destination\"]).invoke(x[\"question\"]))\n",
    "\n",
    "    return full_chain\n",
    "\n",
    "# --- MAIN ---\n",
    "\n",
    "def init_existing_vector_store():\n",
    "    # client = get_qdrant_client()\n",
    "    client = QdrantClient(\n",
    "        url=os.environ['QDRANT_URL'],\n",
    "        api_key=os.environ['QDRANT_API_KEY']\n",
    "    )\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    return QdrantVectorStore(\n",
    "        client=client, \n",
    "        collection_name=COLLECTION_NAME, \n",
    "        embedding=embeddings\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ —É–∂–µ —Å–æ–∑–¥–∞–Ω–Ω–æ–π –±–∞–∑–µ\n",
    "    vector_store = init_existing_vector_store()\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞-–º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä–∞\n",
    "    agent = create_router_agent(vector_store)\n",
    "    print(\"-> –ê–≥–µ–Ω—Ç –≥–æ—Ç–æ–≤! –í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å (–∏–ª–∏ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞).\")\n",
    "    \n",
    "    while True:\n",
    "        user_query = input(\"\\nYou: \")\n",
    "        if user_query.lower() in [\"exit\", \"quit\"]:\n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            response = agent.invoke(user_query)\n",
    "            print(f\"\\nAgent:\\n{response}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
